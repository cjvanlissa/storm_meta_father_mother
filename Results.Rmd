---
title             : "Social reference results"
shorttitle        : "SOCIAL REFERENCE"

author: 
  - name      : "Caspar J. van Lissa"
affiliation   : "1"
corresponding : yes    # Define only one corresponding author
address       : "Padualaan 14, 3584CH Utrecht"
email         : "c.j.vanlissa@uu.nl"

affiliation:
  - id        : "1"
institution   : "Utrecht University, dept. Methodology & Statistics"

authornote: |

abstract: |

keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output: papaja::apa6_docx
---

```{r setup, include = FALSE}
run_everything <- FALSE

library("papaja")
if(!require(motley)){
  library(devtools)
  install_github("cjvanlissa/motley")
  library(motley)
}
library(metafor)
library(metaSEM)

if(run_everything){
  source("data_cleaning.R")
  source("pool_correlation_matrices_robust_se.R")
  source("fit_models.R")
} else {
  load("Overallpooled.RData")
}
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
# To re-run the multigroup analysis:
# source("data_wrangling_multigroup.R")
# source("multigroup_model_constraints.R")
load("subgroups.RData")
load("results_multigroup.RData")
load("par_tables.RData")
load("metafor_t_test.RData")
```



# Analysis

We used meta-analytic structural equation modeling [@cheung2015meta] to
address two
related research questions: Whether behavior similarly affects teacher-student
and peer relationships, and whether teacher-student relationships explain the
association between behavior and peer relationships. Following the
two-stage procedure[see also @cheung2015meta] , we first pooled correlations across studies,
and obtained the asymptotic sampling covariance matrix. 
We used robust variance estimation with bias-reduced
linearization adjustment to account for the fact that several studies
reported multiple effect sizes
[@pustejovskySmallSampleMethodsClusterRobust2018].
Then, a SEM-model was 
fit to the pooled correlation matrix. 

Three subsamples can be identified in the data, based on the time lag between
variables. Behavioral problems, being the primary exogenous variable, were
always coded at time 1. For one group of studies, peer-relationship and 
teacher-student relationship quality were also coded at time 1. This subset
of studies will be referred to as the *cross-sectional* sample. For another 
subset, teacher-student relationship quality was coded at time 1, but 
peer-relationship quality was coded at a later time. This allows us to estimate
time-lagged relationships from behavior and teacher-student relationship 
quality, to peer relationship quality. This subset will be referred to as the
*teacher-first* sample. Finally, in a third subset, which will be referred to as
the *peer-first* sample, teacher-student relationship was coded at a later time
than the other variables.

## Estimating the total N per sample

The N for each effect size was not
coded unambiguously. Specifically, metaSEM requires one N for each correlation
matrix, but in our data, N was coded per correlation coefficient. 
Furthermore, our data included many studies with multiple effect sizes. It was 
not always clear whether these effect sizes originated from the same sample.
We computed <!--two alternative estimates for the
total N across
studies: A--> a lower bound estimate for N, which assumed that each study was
based on only
a single sample, and consisted of the sum the smallest sample size coded for
each study ID. <!--A more liberal estimate summed the unique sample sizes coded for
each study; the underlying assumption being that correlations derived from the
same sample would have been 
reported as having the same N. However, sensitivity analyses indicated that 
there were no differences in results between these two estimates of N, at least
to the third decimal. We used the lower bound estimate of N to err on the side
of caution.-->
The estimated total sample sizes were 
$N = `r subgroups[["Cross-sectional"]][["N_min"]]`$ for the cross-sectional
sample,
$N = `r subgroups[["Teacher first"]][["N_min"]]`$ for the teacher-first 
sample, and
$N = `r subgroups[["Peer first"]][["N_min"]]`$ for the peer-first sample.

## Establishing direction of effects

To establish causality, three conditions must be met: Variables must be 
correlated; one must precede the other in time, and all alternative explanations
must be excluded. The former two of these conditions can be examined here.
Moreover, by comparing coefficients of the cross-sectional model to those of the
time-lagged models, we can gather additional support for the proposed direction
of effects implied by our theoretical model.

We estimated several models (see Table \@ref(tab:tabfitmetasem)). In Model 1, 
we estimated the hypothesized structural
model in all three groups, allowing all parameters to vary freely. In Model 2, 
we 
imposed constraints on the cross-sectional parameters in all three groups, 
allowing only the time-lagged effects to vary freely. In Model 3, we constrained
all
parameters to be the same accross groups, to establish that there were indeed
significant differences between the cross-sectional and time-lagged parameters.
As the table illustrates, likelihood ratio tests indicated that, as expected, 
the fit of Model
2 was not significantly worse than that of Model 1, and the fit of Model 3 was
significantly worse than that of Model 2. We conclude that some of the 
time-lagged parameters differed significantly from the cross-sectional 
parameters, and proceed with analyses using Model 2. Figure 
\@ref(fig:figmultigroup) illustrates the model coefficients by group.

```{r figmultigroup, out.width = "100%", fig.cap="Model coefficients by group. c = constrained parameter."}
knitr::include_graphics("sem_plot.png")
```

<!--that should be identical between groups: For
example, in the teacher-first sample, behavioral problems and teacher-student
relationships were both measured at time 1. The relationship between them should
therefore be the same as in the cross-sectional sample/-->

```{r tabfitmetasem, results = "asis"}
tab_fit$base <- c("1. Free model", "2. Constrain cross-sectional", "3. Constrain all")
names(tab_fit) <- c("Model", "Parameters", "-2LL", "$\\Delta$-2LL", "p")
apa_table(tab_fit, caption = 
"Model fit table", note = "p-values indicate significance of likelihood ratio tests, comparing each model to the one above.", escape = FALSE)
write.csv(tab_fit, "table_fit_metasem.csv", row.names = FALSE)
```

## Results

### Mediation model

We found evidence for the hypothesized significant effect of
behavior on peer relationship quality, and the size of this direct effect 
did not differ across the three samples. Similarly, we found a significant
effect of behavior on teacher-student relationship quality, 
and the size of this direct effect 
did not differ across samples. We also found a significant effect of
teacher-student relationship quality on peer relationship quality in all three 
samples. Finally, we found the hypothesized indirect effect from 
behavior, 
through teacher-student relationship quality, to peer relationship quality. This
indirect effect was significant in all three samples. Our findings thus suggest
that the effect of behavior on peer relationships might be partially mediated
by its effect on teacher-student relationships.

### Direction of effect

Although the indirect effect was significantly larger in the cross-sectional
sample than in
the two time-lagged samples, but did not differ significantly between 
the peer-first and teacher-first samples. Thus, the hypothesized 
mediation model was supported in all three samples, but there were no 
differences between the two time-lagged samples that might support the 
hypothesized direction of effects.

### Effect of behavior on teacher-student and peer relationships

To address the question whether behavior similarly affects teacher-student and
peer relationships, we computed a confidence interval for the difference between
the effect of behavior on teacher-student relationships, and the total effect of
behavior on peer relationships (direct and indirect effect taken together). In 
the cross-sectional sample, but not in the two time-lagged samples, there was a
significant but small difference, favoring the effect on peer relatioships. 
Thus, behavior seems to affect peer and teacher-student relationships similarly,
with slight evidence that the effect on peer relationships is stronger.


```{r tabresults_tf, results = "asis"}
par_table_tf[is.na(par_table_tf)] <- ""
rownames(par_table_tf) <- NULL
apa_table(par_table_tf, caption = 
            "Model results for cross-sectional (cs) and teacher first (tf) samples", note = "*: CI does not include zero. Result is significant with p < .05", escape = TRUE)
write.csv(par_table_tf, "table_param_tf.csv", row.names = FALSE)
```


```{r tabresults_pf, results = "asis"}
par_table_pf[is.na(par_table_pf)] <- ""
rownames(par_table_pf) <- NULL
apa_table(par_table_pf, caption = 
            "Model results for cross-sectional (cs) and\npeer first (pf) samples", 
          note = "*: CI does not include zero. Result is significant with p < .05", escape = TRUE)
write.csv(par_table_pf, "table_param_pf.csv", row.names = FALSE)
```

```{r tabresults_pf_tf, results = "asis"}
par_table_pf_tf[is.na(par_table_pf_tf)] <- ""
rownames(par_table_pf_tf) <- NULL
apa_table(par_table_pf_tf, caption = 
            "Model results for peer first (pf) and\nteacher first (tf) samples", 
          note = "*: CI does not include zero. Result is significant with p < .05", escape = TRUE)
write.csv(par_table_pf_tf, "table_param_pf_tf.csv", row.names = FALSE)
t_test_results <- t_test_coef(model.full, 1, 2)
```



## Is the association between teacher-student and peer relationships stronger for classmate perceptions?

To determine whether the association between teacher-student and 
peer relationship quality was stronger for classmate-reported teacher-student 
relationships, we used meta-regression, with the correlation between 
teacher-student and peer relationship quality as the dependent variable, and a
binary moderator that indicated whether teacher-student relationship quality was
peer-reported, or self-reported. To account for the multilevel structure of the
data, we used a three-level meta-analysis; a somewhat more elegant solution than
the robust variance estimation used for the metaSEM models, which also allows us
to quantify the amount of heterogeneity at the within-study and 
between-studies levels [@vandennoortgateMetaanalysisMultipleOutcomes2015]. It 
should be noted that, like a t-test, this analysis assumes that the residual
heterogeneity is homogenous for peer-reported and self-reported effect sizes.

Our analysis indicated that the correlation between teacher-student and 
peer relationship quality was stronger for classmate-reported teacher-student 
relationships, $\bar{r} `r report(model.full[["b"]][1])`$, 95% CI 
$[`r report(model.full[["ci.lb"]][1], equals = F)`, 
`r report(model.full[["ci.ub"]][1], equals = F)`]$, than for self-reported
teacher-student relationship quality,
$\bar{r} `r report(model.full[["b"]][2])`$, 95% CI 
$[`r report(model.full[["ci.lb"]][2], equals = F)`, 
`r report(model.full[["ci.ub"]][2], equals = F)`]$. A t-test of the model 
parameters indicated that this difference was significant,
$t(`r t_test_results[["df"]]`) = `r formatC(t_test_results[["t"]], digits = 2, format = "f")`, p `r report(t_test_results[["p"]])`$.

As indicated in Table \@ref(tab:variancetable),
the within-study variance component of this analysis differed 
significantly from zero, $\sigma^2_w `r report(model.full[["sigma2"]][1])`$, 
95% CI [`r report(confints[[1]][["random"]][1,2], equals = F)`, 
`r report(confints[[1]][["random"]][1,3], equals = F)`]. 
The between-studies variance component was also significant, and substantially 
larger than the within-studies variance component;
$\sigma^2_b `r report(model.full[["sigma2"]][2])`$, 
95% CI [`r report(confints[[2]][["random"]][1,2], equals = F)`,
`r report(confints[[2]][["random"]][1,3], equals = F)`]. 
Thus, the variation in observed effect sizes was primarily due to differences
between studies. 



```{r variancetable, results = "asis"}
apa_table(aov_table, caption = 
            "Comparing the fit of different multi-level models")
write.csv(aov_table, "table_multilevel_fit.csv", row.names = FALSE)
```

<!--See Table \@ref(tab:tabresults_tf)-->




\newpage

# References
```{r create_r-references}
#lapply(paste('package:',names(sessionInfo()$otherPkgs),sep=""),detach,character.only=TRUE,unload=TRUE)
#library(metafor)
##library(papaja)
#library(metaSEM)
#library(robumeta)
#r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
